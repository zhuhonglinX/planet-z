# Logistic Regression 分析

## 概率分布

Logistic Regression 其实是一种基于概率的分类模型。

假设现在有两个类别 $C_1$ 和 $C_2$，训练集总共包含 $a+b$ 个样本，其中 $a$ 个样本属于 $C_1$，$b$ 个样本属于 $C_2$ ，现在输入一组 n 个特征的样本，$x=[x_1, x_2, \cdots, x_n]^T$，LR 模型需要判别这个样本属于哪一类， $C_1$ 或 $C_2$。

从概率的角度，判别样本的类型，可以用条件概率表示：
$$
P(C_1|x)
$$
由贝叶斯公式得：
$$
P(C_1|x) = \frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1) + P(x|C_2)P(C_2)}
$$
同理，可以求出两个分类各自的概率，然后比较一下大小，我们选择概率大的对应的类型作为样本的预测值。

所以现在的问题变成了如何求等式右边的值。例如，如何求 $P(x|C_1)$，也就是在已知是 $C_1$ 分类下，取得 $x$ 这个样本的概率。要知道一种分类之下有许多样本，真实数量远超 $a$ 个，我们只是抽取了 $a$ 数量作为训练集而已。于是只能进行假设，比如，假设全部空间的样本的分布是服从正态分布（高斯分布）的，那么只要知道高斯分布的概率密度函数，然后代入参数 $x$，就可以求出概率了。

梳理一下逻辑：

1. 我们假定样本服从高斯分布，即 $C_1$ 所有可能样本服从一个高斯分布，$C_2$ 所有可能的样本服从另一个高斯分布。

2. 那么如何求出这两个高斯分布，这个是反向考虑的，假设对于 $C_1$ 的高斯分布已经存在了，并且这个高斯分布保证了选取训练集的 $a$ 个样本的概率为最大。（所以得到了这些作为训练集）
3. 假设 $a$ 个样本独立同分布，然后应用极大似然估计

已知高斯分布的概率密度函数：
$$
f_{\mu,\Sigma} = \frac{1}{(2 \pi)^{D/2}} \frac{1}{|\Sigma|^{1/2}} exp\{ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \}
$$

根据假设，这个高斯分布取出 $a$ 个训练样本的概率应当为最大，所以进行极大似然估计如下：

$$
L(\mu, \Sigma) = f_{\mu, \Sigma}(x^{(1)})f_{\mu, \Sigma}(x^{(2)}) \cdots f_{\mu, \Sigma}(x^{(a)}) \\
\mu^*, \Sigma^* = arg \enspace max L(\mu, \Sigma)
$$

根据极大似然估计的解法，解出：
$$
\mu^* = \frac{1}{a}\sum^a_{i=1}x^{(i)} \\
\Sigma^* = \frac{1}{a}\sum^a_{i=1}(x^{(i)}-\mu^*)(x^{(i)}-\mu^*)^T
$$
这样就求出了 $C_1$ 这种类别的概率分布，那就可以计算出 $P(x|C_1)$，也就是把 $x$ 代入概率密度函数即可。



## 逻辑回归

上面一章再往后面推是可以求出概率的，也就是能够使用概率模型进行分类了，但是往另外一条路走，就得出了 Logistic Regression（逻辑回归）。

逻辑回归对于公式化简：
$$
P(C_1|x) = \frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1) + P(x|C_2)P(C_2)} = \frac{1}{1 + \frac{P(x|C_2)P(C_2)}{P(x|C1)P(C_1)}} = \frac{1}{1+exp(-z)} = \sigma(z) \\
when \quad z = ln\frac{P(x|C_1)P(C_1)}{P(x|C2)P(C_2)}
$$
从概率模型推出了 sigmod function，接下去对 $z$ 化简。

已知：
$$
P(x|C_1) = \frac{1}{(2 \pi)^{D/2}} \frac{1}{|\Sigma|^{1/2}} exp\{ -\frac{1}{2}(x-\mu^1)^T\Sigma^{-1}(x-\mu^1) \} \\
P(x|C_2) = \frac{1}{(2 \pi)^{D/2}} \frac{1}{|\Sigma|^{1/2}} exp\{ -\frac{1}{2}(x-\mu^2)^T\Sigma^{-1}(x-\mu^2) \}
$$
这里公式来自上一节的推理，但是做了一个小改动，就是假设 $C_1$ 和  $C_2$ 共享了同一个  $\Sigma$（近似处理）。

然后处理 $z$
$$
\begin{align*}
z & = ln\frac{P(x|C_1)}{P(x|C2)} + ln\frac{P(C_1)}{P(C_2)} = ln\frac{P(x|C_1)}{P(x|C2)} +ln\frac{a}{b} \\
& = \cdots \\
& = (\mu^1-\mu^2)^T\Sigma^{-1}x-\frac{1}{2}(\mu^1)^T\Sigma^{-1}\mu^1+\frac{1}{2}(\mu^2)^T\Sigma^{-1}\mu^2+ln\frac{a}{b}
\end{align*}
$$
最后这个公式，会发现，$(\mu^1-\mu^2)^T\Sigma^{-1}$ 是一个行向量乘一个矩阵，得到一个行向量，所以看成 $w^T$。之后的一串其实是一个数，所以直接看成 $b$ 。

所以：
$$
P(C_1|x) = \sigma(z) = \sigma(w^Tx+b)
$$
