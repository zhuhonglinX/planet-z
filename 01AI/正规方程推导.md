# 正规方程推导

## 已知条件

对于线性模型，我们写出代价函数：
$$
J(\theta) = \frac{1}{2m} \sum_{i=1}^{m}(\theta^T x^{(i)} - y^{(i)})^2
$$
现在用 $X$ 来表示所有训练样本：
$$
X =\left [ \begin{matrix} x^{(1)} \\ x^{(2)} \\ \vdots \\ x^{(m)} \end{matrix} \right ] = \left [ \begin{matrix} x_0^{(1)} & \cdots & x_n^{(1)} \\ \vdots && \vdots \\ x_0^{(m)} & \cdots & x_n^{(m)} \end{matrix} \right ]
$$

$\theta$ 和 $Y$ 分别表示：$\theta = \left [ \theta_0, \theta_1, \cdots, \theta_n \right ]^T$，$Y=[y^{(1)}, y^{(2)}, \cdots, y^{(m)}]^T$。

我们的目的是要算出使得 $J(\theta)$ 最小化的 $\theta$ 值。



## 推导

首先看一下：
$$
X \cdot \theta - Y = \left[ \begin{matrix} x^{(1)} \cdot \theta - y^{(1)} \\ x^{(2)} \cdot \theta - y^{(2)} \\ \vdots \\ x^{(m)} \cdot \theta -y^{(m)} \end{matrix} \right]_{m \times 1} \\
$$

对于列矩阵，它的转置点乘它本身，就可以得到一个累加的数：
$$
(X \cdot \theta - Y)^T(X \cdot \theta - Y) = \sum_{i=1}^{m}(\theta^T x^{(i)} - y^{(i)})^2
$$

所以代价函数表示为：
$$
J(\theta) = \frac{1}{2m} (X \cdot \theta - Y)^T(X \cdot \theta - Y) = \frac{1}{2m}(Y^TY-Y^TX\theta - \theta^TX^TY + \theta^TX^TX\theta)
$$

$$
\frac{\partial J(\theta)}{\partial \theta} = \frac{1}{2m}(\frac{\partial Y^TY}{\partial \theta}-\frac{\partial Y^TX\theta}{\partial \theta}-\frac{\partial \theta^TX^TY}{\partial \theta}+\frac{\partial \theta^TX^TX\theta}{\partial \theta})
$$



于是计算每一项的偏导：
$$
\frac{\partial Y^TY}{\partial \theta} = 0
$$

$$
\frac{\partial Y^TX\theta}{\partial \theta} = \left[ \begin{matrix} \frac{\partial Y^TX\theta}{\partial \theta_0}, \frac{\partial Y^TX\theta}{\partial \theta_1}, \cdots, \frac{\partial Y^TX\theta}{\partial \theta_n} \end{matrix} \right]^T = \left [ \begin{matrix} x_0^{(1)}y^{(1)} + \cdots + x_0^{m}y^m \\ \vdots \\ x_n^{(1)}y^{(1)} + \cdots+ x_n^{(m)}y^{(m)} \end{matrix} \right] = X^TY
$$

同理计算之后两项：
$$
\frac{\partial \theta^TX^TY}{\partial \theta} = X^TY
$$

$$
\frac{\partial \theta^TX^TX\theta}{\partial \theta} = 2X^TX\theta
$$



所以，
$$
\frac{\partial J(\theta)}{\partial \theta} = \frac{1}{2m}(-2X^TY + 2X^TX\theta) = 0
$$
解得 $\theta$：
$$
\theta = (X^TX)^{-1}X^TY
$$




